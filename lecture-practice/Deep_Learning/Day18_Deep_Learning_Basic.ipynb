{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nKprUHBVaAR0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])"
      ],
      "metadata": {
        "id": "Lgu_-J56aNO7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "id": "hMe4saw0aSla"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)"
      ],
      "metadata": {
        "id": "rKsDX62vaW1F"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CafvZFEOaf_f",
        "outputId": "5dee200e-e49c-4d35-d8bc-06bdd0130c2c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9765, -0.8588,\n",
              "           -0.8588, -0.8588, -0.0118,  0.0667,  0.3725, -0.7961,  0.3020,\n",
              "            1.0000,  0.9373, -0.0039, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -0.7647, -0.7176, -0.2627,  0.2078,  0.3333,  0.9843,\n",
              "            0.9843,  0.9843,  0.9843,  0.9843,  0.7647,  0.3490,  0.9843,\n",
              "            0.8980,  0.5294, -0.4980, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -0.6157,  0.8667,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
              "            0.9843,  0.9843,  0.9843,  0.9686, -0.2706, -0.3569, -0.3569,\n",
              "           -0.5608, -0.6941, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -0.8588,  0.7176,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
              "            0.5529,  0.4275,  0.9373,  0.8902, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -0.3725,  0.2235, -0.1608,  0.9843,  0.9843,  0.6078,\n",
              "           -0.9137, -1.0000, -0.6627,  0.2078, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -0.8902, -0.9922,  0.2078,  0.9843, -0.2941,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000,  0.0902,  0.9843,  0.4902,\n",
              "           -0.9843, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -0.9137,  0.4902,  0.9843,\n",
              "           -0.4510, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.7255,  0.8902,\n",
              "            0.7647,  0.2549, -0.1529, -0.9922, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3647,\n",
              "            0.8824,  0.9843,  0.9843, -0.0667, -0.8039, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -0.6471,  0.4588,  0.9843,  0.9843,  0.1765, -0.7882, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -0.8745, -0.2706,  0.9765,  0.9843,  0.4667, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000,  0.9529,  0.9843,  0.9529, -0.4980,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -0.6392,  0.0196,  0.4353,  0.9843,  0.9843,  0.6235, -0.9843,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.6941,  0.1608,\n",
              "            0.7961,  0.9843,  0.9843,  0.9843,  0.9608,  0.4275, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -0.8118, -0.1059,  0.7333,  0.9843,\n",
              "            0.9843,  0.9843,  0.9843,  0.5765, -0.3882, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -0.8196, -0.4824,  0.6706,  0.9843,  0.9843,  0.9843,\n",
              "            0.9843,  0.5529, -0.3647, -0.9843, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8588,\n",
              "            0.3412,  0.7176,  0.9843,  0.9843,  0.9843,  0.9843,  0.5294,\n",
              "           -0.3725, -0.9294, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -0.5686,  0.3490,  0.7725,\n",
              "            0.9843,  0.9843,  0.9843,  0.9843,  0.9137,  0.0431, -0.9137,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000,  0.0667,  0.9843,  0.9843,\n",
              "            0.9843,  0.6627,  0.0588,  0.0353, -0.8745, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]]),\n",
              " 5)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        # input layer\n",
        "        self.fc1 = nn.Linear(28*28, 128)\n",
        "        # output layer\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "\n",
        "    # Feed Forward\n",
        "    def forward(self, x):\n",
        "      # Turn image into 1D\n",
        "      x = x.view(-1, 28*28)\n",
        "      # Hidden Layer: ReLu(Activation Function)\n",
        "      x = F.relu(self.fc1(x))\n",
        "      # Output Layer\n",
        "      x = F.relu(self.fc2(x))\n",
        "      # Using SoftMax for Output Layer\n",
        "      return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "PvR_oXT6atNy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleNN()\n",
        "\n",
        "# Loss Function and Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
      ],
      "metadata": {
        "id": "eO5dg9IvbaS2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Training\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "  model.train()\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    loss = criterion(output, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if batch_idx % 100 == 0:\n",
        "      print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
        "            f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n"
      ],
      "metadata": {
        "id": "1AWfOg0HbmRM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Testing\n",
        "def test(model, device, test_loader):\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      output = model(data)\n",
        "      test_loss += criterion(output, target).item()  # 손실 합산\n",
        "      pred = output.argmax(dim=1, keepdim=True)  # 가장 높은 확률을 가진 클래스 예측\n",
        "      correct += pred.eq(target.view_as(pred)).sum().item()  # 맞춘 개수 합산\n",
        "\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "  test_accuracy = 100. * correct / len(test_loader.dataset)\n",
        "  print(f'Test set: Average loss: {test_loss:.4f}, Accuracy: {test_accuracy:.2f}%')\n",
        "  return test_loss, test_accuracy"
      ],
      "metadata": {
        "id": "Bm6pm4Pdb6lC"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Training & Testing Execution\n",
        "# Setting\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "epochs = 1\n",
        "train_losses, test_losses, test_accuracies = [], [], []\n",
        "\n",
        "# Excute!\n",
        "for epoch in range(1, epochs + 1):\n",
        "  train(model, device, train_loader, optimizer, epoch)\n",
        "  test_loss, test_accuracy = test(model, device, test_loader)\n",
        "  test_losses.append(test_loss)\n",
        "  test_accuracies.append(test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKHm3B1TciEL",
        "outputId": "096dbb7d-a857-49ab-949f-e0ec5ce2f9b6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.158166\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.163301\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.155440\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.108277\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.114343\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.210668\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.079261\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.301955\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.103289\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.212476\n",
            "Test set: Average loss: 0.0001, Accuracy: 96.25%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary of the trained model\n",
        "from torchsummary import summary\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hazG-fsyc8QY",
        "outputId": "3f5461a9-dfa8-4531-b140-9a0091ccb23e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 128]         100,480\n",
            "            Linear-2                   [-1, 64]           8,256\n",
            "================================================================\n",
            "Total params: 108,736\n",
            "Trainable params: 108,736\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.41\n",
            "Estimated Total Size (MB): 0.42\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}